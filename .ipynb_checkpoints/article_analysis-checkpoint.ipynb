{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News articles data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Before we make our wordclouds and apply classification and clustering methods to our data,\n",
    "    we make sure to run *generate_train_test_sets.ipynb*, in order to create the train and test sets.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"data.tsv\", sep='\\t', encoding = 'ANSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Word Clouds per Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the wordclouds we need all the data we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes as parameter a string representing one of the dataframe's categories,\n",
    "and returns all the articles' content in that category as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_category_content(category: str) -> str:\n",
    "    articles_series = df[df['category'] == category]['content']\n",
    "    words = ' '.join(articles_series)\n",
    "    return words\n",
    "\n",
    "def wordcloud_gen(category):\n",
    "    wordcloud = WordCloud(\n",
    "        width = 1600,\n",
    "        height = 1000,\n",
    "        background_color = \"white\",\n",
    "        min_font_size = 10).generate(choose_category_content(category))\n",
    "\n",
    "    plt.figure(figsize = (16, 10), facecolor = None) \n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# entertainment_wc = WordCloud(width=1920, background_color = 'white', height=1080).generate(choose_category_content('entertainment'))\n",
    "\n",
    "# politics_wc = WordCloud(width=1920, background_color = 'white', height=1080).generate(choose_category_content('politics'))\n",
    "\n",
    "# sport_wc = WordCloud(width=1920, background_color = 'white', height=1080).generate(choose_category_content('sport'))\n",
    "\n",
    "# tech_wc = WordCloud(width=1920, background_color = 'white', height=1080).generate(choose_category_content('tech'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# wordcloud_gen(\"business\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entertainment Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud_gen(\"entertainment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politics Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud_gen(\"politics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud_gen(\"sport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud_gen(\"tech\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just a few worth-reading observations regarding the wordclouds\n",
    "First of all, most of the words in each word clouds are pretty relevant to the respective categories.\n",
    "Another interesting thing is the word **said**. One quick logical thought is that it would alter the classification results, either little or more, it doesn't matter.\n",
    "\n",
    "We can prove that it won't, by doing a chi-squared test on our data.\n",
    "\n",
    "Chi-squared test can measure \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['category_id'] = df.category.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf = TfidfVectorizer(max_features = 100, ngram_range = (1, 2))\n",
    "\n",
    "# features = tf_idf.fit_transform(df.content).toarray()\n",
    "# features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import chi2\n",
    "# N = 2\n",
    "# labels = df.category_id\n",
    "# for category, category_id in sorted(category_to_id.items()):\n",
    "#     features_chi2 = chi2(features, labels == category_id)\n",
    "#     indices = np.argsort(features_chi2[0])\n",
    "#     feature_names = np.array(tf_idf.get_feature_names())[indices]\n",
    "#     unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "#     bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "#     print(\"# '{}':\".format(category))\n",
    "#     print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "#     print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import make_scorer,    \\\n",
    "                            accuracy_score, \\\n",
    "                            precision_score,\\\n",
    "                            recall_score,   \\\n",
    "                            f1_score,       \\\n",
    "                            classification_report\n",
    "\n",
    "train_set = pd.read_csv(\"train_set.tsv\", sep='\\t', encoding = 'ANSI')\n",
    "test_set = pd.read_csv(\"test_set.tsv\", sep='\\t', encoding = 'ANSI')\n",
    "test_labels = pd.read_csv(\"test_labels.tsv\", sep='\\t', encoding = 'ANSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the content and category columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content = train_set['content']\n",
    "train_labels = train_set['category']\n",
    "test_content = test_set['content']\n",
    "test_categories = test_labels['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the train and test labels using sklearn.preprocessing.LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Transform our text data using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "count_vec = CountVectorizer(max_features=500,ngram_range=(1,2))\n",
    "\n",
    "cv_train_content = count_vec.fit_transform(train_content)\n",
    "cv_test_content = count_vec.transform(test_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers cross validation and Evaluating predicted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perform a grid search to tune the model and see which parameters work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "            'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "}\n",
    "clf = GridSearchCV(svm_clf, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the train data into the grid search and show the best parameters for the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1000.0, 5000.0, 10000.0, 50000.0, 100000.0],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
       "                         'kernel': ['rbf', 'linear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(cv_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000.0, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've found the best parameters, use them to perform the cross validation and test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='rbf',C=1000, gamma=0.0001)\n",
    "svm_clf.fit(cv_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform a 10-Fold Cross Validation on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores = cross_validate(svm_clf, cv_train_content, train_labels, scoring=scoring, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.1875282049179077\n",
      "score_time 0.13688256740570068\n",
      "test_precision_macro 0.9469065702600578\n",
      "test_recall_macro 0.9441582262903015\n",
      "test_f1_macro 0.9445829206432208\n",
      "test_accuracy 0.9460674157303371\n"
     ]
    }
   ],
   "source": [
    "for i in svm_scores:\n",
    "    print(i,svm_scores[i].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed to predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = svm_clf.predict(cv_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9658951358880079\n",
      "0.9600700280112046\n",
      "0.9622641221420061\n",
      "0.9617977528089887\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_labels, predicted_labels, average='macro'))\n",
    "print(recall_score(test_labels, predicted_labels, average='macro'))\n",
    "print(f1_score(test_labels, predicted_labels, average='macro'))\n",
    "print(accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(cv_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 3.070152688026428\n",
      "score_time 0.09425168037414551\n",
      "test_precision_macro 0.9564136933030689\n",
      "test_recall_macro 0.9531539564899703\n",
      "test_f1_macro 0.9540699869475532\n",
      "test_accuracy 0.955056179775281\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_validate(rf_clf, cv_train_content, train_labels, scoring=scoring, cv=10)\n",
    "for i in rf_scores:\n",
    "    print(i,rf_scores[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_predicted_labels = rf_clf.predict(cv_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958214709445628\n",
      "0.9535383244206773\n",
      "0.9552606029641464\n",
      "0.9550561797752809\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_labels, rd_predicted_labels, average='macro'))\n",
    "print(recall_score(test_labels, rd_predicted_labels, average='macro'))\n",
    "print(f1_score(test_labels, rd_predicted_labels, average='macro'))\n",
    "print(accuracy_score(test_labels, rd_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf.fit(cv_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.005485796928405761\n",
      "score_time 0.006685829162597657\n",
      "test_precision_macro 0.9480210261769069\n",
      "test_recall_macro 0.9477503527195873\n",
      "test_f1_macro 0.9472689646923363\n",
      "test_accuracy 0.948876404494382\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_validate(mnb_clf, cv_train_content, train_labels, scoring=scoring, cv=10)\n",
    "for i in rf_scores:\n",
    "    print(i,rf_scores[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_predicted_labels = mnb_clf.predict(cv_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9622892355322696\n",
      "0.9616749427043546\n",
      "0.961929996436564\n",
      "0.9617977528089887\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(recall_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(f1_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(accuracy_score(test_labels, mnb_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Transform our text data using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer(max_features=300, ngram_range=(1,2))\n",
    "\n",
    "tfidf_train_content = tfidf_vec.fit_transform(train_content)\n",
    "tfidf_test_content = tfidf_vec.transform(test_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "            'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "}\n",
    "clf = GridSearchCV(SVC(), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the train data into the grid search and show the best parameters for the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(tfidf_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've found the best parameters, use them to perform the cross validation and test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0005, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='rbf',C=1000, gamma=0.0005)\n",
    "\n",
    "svm_clf.fit(tfidf_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform a 10-Fold Cross Validation on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores = cross_validate(svm_clf, tfidf_train_content, train_labels, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.0540414333343506\n",
      "score_time 0.27834105491638184\n",
      "test_precision_macro 0.9489600565531576\n",
      "test_recall_macro 0.9481579969533429\n",
      "test_f1_macro 0.9483229705505785\n",
      "test_accuracy 0.949438202247191\n"
     ]
    }
   ],
   "source": [
    "for i in svm_scores:\n",
    "    print(i,svm_scores[i].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed to predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = svm_clf.predict(tfidf_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9658356311643737\n",
      "0.9634536541889483\n",
      "0.964450851635213\n",
      "0.9640449438202248\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_labels, predicted_labels, average='macro'))\n",
    "print(recall_score(test_labels, predicted_labels, average='macro'))\n",
    "print(f1_score(test_labels, predicted_labels, average='macro'))\n",
    "print(accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(tfidf_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.7234101295471191\n",
      "score_time 0.06059713363647461\n",
      "test_precision_macro 0.9449434268335754\n",
      "test_recall_macro 0.9417875686123782\n",
      "test_f1_macro 0.9427747764962021\n",
      "test_accuracy 0.9438202247191011\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_validate(rf_clf, tfidf_train_content, train_labels, scoring=scoring)\n",
    "for i in rf_scores:\n",
    "    print(i,rf_scores[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_predicted_labels = rf_clf.predict(tfidf_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9510416698884191\n",
      "0.9442182327476445\n",
      "0.9468950044273738\n",
      "0.946067415730337\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_labels, rd_predicted_labels, average='macro'))\n",
    "print(recall_score(test_labels, rd_predicted_labels, average='macro'))\n",
    "print(f1_score(test_labels, rd_predicted_labels, average='macro'))\n",
    "print(accuracy_score(test_labels, rd_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf.fit(tfidf_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.008976411819458009\n",
      "score_time 0.008979415893554688\n",
      "test_precision_macro 0.9398194444961249\n",
      "test_recall_macro 0.9356126834486863\n",
      "test_f1_macro 0.9371527975029984\n",
      "test_accuracy 0.9387640449438202\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_validate(mnb_clf, tfidf_train_content, train_labels, scoring=scoring)\n",
    "for i in rf_scores:\n",
    "    print(i,rf_scores[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_predicted_labels = mnb_clf.predict(tfidf_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9439110539110539\n",
      "0.9405347593582889\n",
      "0.9420072594647889\n",
      "0.9415730337078652\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(recall_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(f1_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(accuracy_score(test_labels, mnb_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Beat the Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to improve the model based on Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function prototype for text preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:DeepPink\">**preprocess_article**</span>**(text)**  \n",
    "&nbsp;&nbsp;Removes special characters from a given string object, removes stop words and lematizes words using WordNetLematizer().  \n",
    "&nbsp;&nbsp;&nbsp;**Parameters: &nbsp;&nbsp;&nbsp;text : str**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "String object to process. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**Returns: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;text : str**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Lowercase lematized string object without stopwords and several special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "stop_words = list(stop_words)\n",
    "\n",
    "\"\"\" In previous version of our project, the wordclouds below showed that 'said' and 'say' words\n",
    "    appear the most in the data, so we decided to remove them as they has no valuable meaning. \"\"\"\n",
    "# stop_words.extend(['said','say'])\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\"\"\" Make sure that the text parameter and return variable are of string type. \"\"\"\n",
    "def preprocess_article(text: str) -> str:\n",
    "    # Remove newlines and \\r characters.\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    \n",
    "    # Remove quotes\n",
    "    text = text.replace('\"', ' ')\n",
    "   \n",
    "    # Convert text to lowercase.\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and many special characters.\n",
    "    text = text.translate(str.maketrans('', '', '!?:\\';.,[]()@#$%^&*Â£'))\n",
    "   \n",
    "    # Remove terminating 's characters.\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "\n",
    "    # Remove stop words. Note: do this first and then lemmatize because lemmatizing\n",
    "    # can change words like 'has' to 'ha'.\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # Lematize text with WordNetLemmatizer().\n",
    "    text = ' '.join([wordnet_lemmatizer.lemmatize(word) for word in text.split(' ')])\n",
    "    \n",
    "    # Remove all words with numbers in them (ie. 400bn, 512kbps etc.) .\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content = train_content.apply(preprocess_article)\n",
    "test_content = test_content.apply(preprocess_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      playing politics security nation michael howar...\n",
       "1      film-maker spike lee say black representation ...\n",
       "2      johnny vaughan denise van outens saturday nigh...\n",
       "3      annual academy award taking place february sta...\n",
       "4      arsenal vice-chairman david dein said club con...\n",
       "                             ...                        \n",
       "440    luxury cruise liner crystal harmony currently ...\n",
       "441    share elan biogen idec plunged monday firm sus...\n",
       "442    manchester united winger cristiano ronaldo sai...\n",
       "443    australian wing david campese told england sto...\n",
       "444    leonardo dicaprio jamie foxx hilary swank atte...\n",
       "Name: content, Length: 445, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tfidf_vec = TfidfVectorizer(max_features=300, ngram_range=(1,2))\n",
    "\n",
    "# tfidf_train_content = tfidf_vec.fit_transform(train_content)\n",
    "# tfidf_test_content = tfidf_vec.transform(test_content)\n",
    "\n",
    "count_vec = CountVectorizer(max_features=500,ngram_range=(1,2))\n",
    "\n",
    "cv_train_content = count_vec.fit_transform(train_content)\n",
    "cv_test_content = count_vec.transform(test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "            'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "}\n",
    "clf = GridSearchCV(SVC(), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the train data into the grid search and show the best parameters for the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1000.0, 5000.0, 10000.0, 50000.0, 100000.0],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
       "                         'kernel': ['rbf', 'linear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(tfidf_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000.0, 'gamma': 0.0005, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf = SVC(kernel='rbf',C=1000, gamma=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0005, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf.fit(tfidf_train_content, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.6890371799468994\n",
      "score_time 0.1812415599822998\n",
      "test_precision_macro 0.9494755974974487\n",
      "test_recall_macro 0.9487769746708979\n",
      "test_f1_macro 0.9488877162256211\n",
      "test_accuracy 0.95\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_validate(mnb_clf, tfidf_train_content, train_labels, scoring=scoring)\n",
    "for i in rf_scores:\n",
    "    print(i,rf_scores[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_predicted_labels = mnb_clf.predict(tfidf_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664536115630558\n",
      "0.9630334861217215\n",
      "0.9643538056226294\n",
      "0.9640449438202248\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(recall_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(f1_score(test_labels, mnb_predicted_labels, average='macro'))\n",
    "print(accuracy_score(test_labels, mnb_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
